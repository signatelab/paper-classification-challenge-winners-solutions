{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SRWS-PSG-TF_提出用.ipynb","provenance":[],"collapsed_sections":["8iPb92wfXWbz","9lD2Z7vgUPId","-3yPF_-RcPNP","TGa8yqv6UT-m"],"mount_file_id":"1aXzrcHlYGvherb7llNXpVqyrqkYB_SLZ","authorship_tag":"ABX9TyPhsJeHeknuew0rV/jf+b8u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"4bVDd4gR8vLG"},"source":["pip install -r drive/MyDrive/SRWS-PSG/config/requirements.txt --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TAWH-wuiclAd"},"source":["## Packages"]},{"cell_type":"code","metadata":{"id":"Ta_sgmHd6BNO"},"source":["import logging\n","import os\n","import pickle\n","import random\n","import re\n","from collections import defaultdict\n","from time import sleep\n","\n","import pandas as pd\n","import numpy as np\n","from adabelief_tf import AdaBeliefOptimizer\n","from omegaconf import OmegaConf\n","\n","from sklearn.metrics import fbeta_score, roc_auc_score\n","from sklearn.model_selection import StratifiedKFold\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras import backend as K\n","\n","import transformers\n","from transformers import (\n","    AutoTokenizer,\n","    AutoConfig,\n","    TFAutoModel,\n",")\n","\n","pd.options.display.precision = 5\n","pd.set_option('max_colwidth', 500)\n","pd.set_option('max_columns', 500)\n","pd.set_option('max_rows', 200)\n","\n","tf.get_logger().setLevel('ERROR')\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ITgwghycgZ4"},"source":["## Parameters"]},{"cell_type":"code","metadata":{"id":"Ub3JrZyYB1AU"},"source":["config_path = '/content/drive/MyDrive/SRWS-PSG/config/test/2021-09-21_235528.yml'\n","args = OmegaConf.load(config_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TuM7oWDwmGFJ"},"source":["if ('cache_dir' in args.keys()) and ('model_dir' in args.keys()):\n","    os.makedirs(args.cache_dir, exist_ok=True)\n","    os.makedirs(args.model_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8iPb92wfXWbz"},"source":["## DataIO"]},{"cell_type":"code","metadata":{"id":"LtlGhbUpXMIu"},"source":["def dump(target, filepath, protocol=3):\n","    with open(filepath, 'wb') as f:\n","        pickle.dump(target, f, protocol=protocol)\n","\n","def load(filepath):\n","    with open(filepath, 'rb') as f:\n","        return pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yaf8l5T7em4"},"source":["def create_logger(dir_path):\n","    logger = logging.getLogger(__name__)\n","    logger.handlers = []\n","    \n","    stream_handler = logging.StreamHandler()\n","    file_handler = logging.FileHandler(os.path.join(dir_path, 'experiment.log'))\n","\n","    formatter = logging.Formatter('[%(asctime)s][%(levelname)s]:%(message)s')\n","    stream_handler.setFormatter(formatter)\n","    file_handler.setFormatter(formatter)\n","\n","    logger.addHandler(stream_handler)\n","    logger.addHandler(file_handler)\n","    logger.setLevel(logging.INFO)\n","    return logger"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q5amXiT6uh8V"},"source":["def read_data(args):\n","    df_train = pd.read_csv(f\"{args.data_dir}/train.csv\")\n","    df_test = pd.read_csv(f\"{args.data_dir}/test.csv\")\n","\n","    df_train.loc[[2488, 7708], 'judgement'] = 0\n","\n","    df_train['abstract'] = df_train['abstract'].fillna(\"\")\n","    df_test['abstract'] = df_test['abstract'].fillna(\"\")\n","    return df_train, df_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZztHRimNUKXZ"},"source":["## Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coKHCvwe7n_-","executionInfo":{"status":"ok","timestamp":1633696686789,"user_tz":-540,"elapsed":20,"user":{"displayName":"Ichikawa Takumi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07019456556681026872"}},"outputId":"6414d012-00e0-4762-c608-9c08677df7d3"},"source":["try:\n","    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', TPU.cluster_spec().as_dict()['worker'])\n","except ValueError:\n","    TPU = None\n","    print('INFO: Not connected to a TPU runtime')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO: Not connected to a TPU runtime\n"]}]},{"cell_type":"code","metadata":{"id":"yBD5BH3o7qiu"},"source":["def build_model(args):\n","    if args.mode == 'train':\n","        transformer = TFAutoModel.from_pretrained(args.model_name, cache_dir=args.cache_dir, from_pt=args.from_pt)\n","    else:\n","        config = AutoConfig.from_pretrained(args.model_name)\n","        transformer = TFAutoModel.from_config(config)\n","    \n","    input_ids = tf.keras.layers.Input(shape=(args.max_length, ), dtype=tf.int32, name='input_ids')\n","    attention_mask = tf.keras.layers.Input(shape=(args.max_length, ), dtype=tf.int32, name='attention_mask')\n","\n","    x = transformer(input_ids, attention_mask=attention_mask)\n","    x = x[0][:, 0, :]\n","    x = tf.keras.layers.Dropout(args.dropout_rate)(x)\n","    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","    model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=[output])\n","\n","    if args.mode == 'train':\n","        optimizer = AdaBeliefOptimizer(**args.optimizer)\n","\n","        model.compile(\n","            optimizer=optimizer,\n","            loss=[tfa.losses.SigmoidFocalCrossEntropy()],\n","        )\n","    \n","    return model\n","\n","\n","def initialize_tpu_and_get_model(args):\n","    if not TPU:\n","        return build_model(args)\n","    \n","    tf.config.experimental_connect_to_cluster(TPU)\n","    tf.tpu.experimental.initialize_tpu_system(TPU)\n","    tpu_strategy = tf.distribute.TPUStrategy(TPU)\n","\n","    with tpu_strategy.scope():\n","        model = build_model(args)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9lD2Z7vgUPId"},"source":["## DataLoader"]},{"cell_type":"code","metadata":{"id":"-GMmlk-BYm7Y"},"source":["class DataProvider:\n","    def __init__(self, df_train, df_test, args):\n","        self.df_train = df_train\n","        self.df_test = df_test\n","        self.tokenizer = AutoTokenizer.from_pretrained(args.model_name, cache_dir=args.cache_dir)\n","        self.args = args\n","\n","        kfold = StratifiedKFold(n_splits=args.n_splits, random_state=args.seed, shuffle=True)\n","        self.indices = list(kfold.split(df_train, df_train[args.target_col]))\n","\n","    def tokenize(self, texts):\n","        inputs = self.tokenizer.batch_encode_plus(\n","            texts,\n","            padding='max_length',\n","            truncation=True,\n","            max_length=self.args.max_length,\n","            return_tensors='tf',\n","        )\n","        return dict(inputs)\n","    \n","    def create_dataset(self, X, y=None, batch_size=None, mode='train'):\n","        data = (X, y) if y is not None else X\n","        dataset = tf.data.Dataset.from_tensor_slices(data)\n","\n","        if mode == 'train':\n","            dataset = dataset.shuffle(2048)\n","        \n","        dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","        if mode == 'train' and self.args.steps_per_epoch:\n","            dataset = dataset.repeat()\n","\n","        return dataset\n","    \n","    def create_train_dataset(self, fold):\n","        train_idx, _ = self.indices[fold]\n","\n","        train_data = self.df_train[self.args.feature_cols].iloc[train_idx]\n","        train_data = self.tokenize(train_data.values.tolist())\n","        train_labels = self.df_train[self.args.target_col].iloc[train_idx].values\n","\n","        train_dataset = self.create_dataset(\n","            train_data, train_labels, self.args.train_batch_size, mode='train')\n","        \n","        return train_dataset\n","    \n","    def create_valid_dataset(self, fold):\n","        _, valid_idx = self.indices[fold]\n","\n","        valid_data = self.df_train[self.args.feature_cols].iloc[valid_idx]\n","        valid_data = self.tokenize(valid_data.values.tolist())\n","        valid_labels = self.df_train[self.args.target_col].iloc[valid_idx].values\n","\n","        valid_dataset = self.create_dataset(\n","            valid_data, valid_labels, self.args.valid_batch_size, mode='valid')\n","        \n","        return valid_dataset, valid_labels\n","\n","    def create_test_dataset(self):\n","        test_data = self.df_test[self.args.feature_cols]\n","        test_data = self.tokenize(test_data.values.tolist())\n","        test_dataset = self.create_dataset(test_data, batch_size=self.args.test_batch_size, mode='test')\n","        return test_dataset\n","    \n","    def create_valid_labels(self, fold):\n","        _, valid_idx = self.indices[fold]\n","        valid_labels = self.df_train[self.args.target_col].iloc[valid_idx].values\n","        return valid_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-3yPF_-RcPNP"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"yklwpU_3PLMB"},"source":["def seed_everything(seed=2021):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    tf.random.set_seed(seed)\n","\n","\n","def optimize_threshold(y_true, y_pred):\n","    best_threshold = 0\n","    best_score = 0\n","\n","    for threshold in np.linspace(0, 1, 1001, dtype=np.float32):\n","        current_preds = (np.asarray(y_pred) > threshold).astype(int)\n","        current_score = fbeta_score(y_true, current_preds, beta=7)\n","\n","        if current_score > best_score:\n","            best_threshold = threshold\n","            best_score = current_score\n","            \n","    return best_threshold\n","\n","\n","def calc_score(y_true, y_pred):\n","    score = {}\n","    score['auc'] = roc_auc_score(y_true, y_pred)\n","\n","    threshold = optimize_threshold(y_true, y_pred)\n","    y_pred = (np.asarray(y_pred) >= threshold).astype(int)\n","\n","    score['threshold'] = threshold\n","    score['fbeta_score'] = fbeta_score(y_true, y_pred, beta=7)\n","    return score\n","\n","\n","def log_metrics(logger, fold, score, epoch=None):\n","    msg = [f'fold: {fold}']\n","\n","    if epoch is not None:\n","        msg += [f'epoch: {epoch}']\n","\n","    for key in score.keys():\n","        msg += [f\"{key}: {score[key]:.5f}\"]\n","\n","    msg = ', '.join(msg)\n","    logger.info(msg)\n","\n","\n","def create_graph(result, args):\n","    dir_path = f\"{args.save_dir}/graphs\"\n","    os.makedirs(dir_path, exist_ok=True)\n","\n","    pd.DataFrame(result.history).plot(ylim=[0, 0.02])\n","    plt.savefig(f\"{dir_path}/fold{args.fold}_history.png\")\n","\n","\n","def read_threshold(filepath):\n","    with open(filepath, 'r') as f:\n","        lines = f.readlines()\n","    \n","    results = []\n","    for line in lines:\n","        match = re.search(r\"best thresholds\", line)\n","        if not match:\n","            continue\n","\n","        thresholds = eval(line[match.span()[1]+2:])\n","        results.append(thresholds)\n","    \n","    return np.round(np.round(results, 3).mean(), 5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TGa8yqv6UT-m"},"source":["## Trainer"]},{"cell_type":"code","metadata":{"id":"vURH8fAHUnRf"},"source":["class CalcMetricAndSaveModel(tf.keras.callbacks.Callback):\n","    def __init__(self, valid_dataset, valid_labels, logger, args):\n","        mode_candidates = {'min': 0, 'max': 1}\n","        params = args.checkpoint\n","\n","        self.valid_dataset = valid_dataset\n","        self.valid_labels = valid_labels\n","        self.logger = logger\n","        self.args = args\n","\n","        self.monitor = params.monitor\n","        self.mode = mode_candidates[params.mode]\n","\n","        self.best_scores = [params.default_score] * params.n_best\n","        self.best_thresholds = [0.1] * params.n_best\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        preds = self.model.predict(self.valid_dataset).reshape(-1)\n","        score = calc_score(self.valid_labels, preds)\n","        score.update(logs)\n","        log_metrics(self.logger, self.args.fold, score, epoch)\n","\n","        idx = np.argmin(self.best_scores)\n","        best_score = self.best_scores[idx]\n","\n","        if self.mode:\n","            judgement = score[self.monitor] > best_score\n","        else:\n","            judgement = score[self.monitor] < best_score\n","\n","        if judgement:\n","            model_path = f\"{self.args.model_dir}/{os.path.basename(self.args.model_name)}_fold{self.args.fold}_{idx}.h5\"\n","            msg = f\"{self.monitor} improved from {best_score:.5f} to {score[self.monitor]:.5f}, \"\n","            msg += f\"saving model to {model_path}\"\n","            self.logger.info(msg)\n","\n","            self.save_model(model_path)\n","\n","            self.best_scores[idx] = score[self.monitor]\n","            self.best_thresholds[idx] = score['threshold']\n","        else:\n","            msg = f\"{self.monitor} did not improve from {best_score:.5f}\"\n","            self.logger.info(msg)\n","        \n","    def on_train_end(self, logs=None):\n","        self.logger.info(f\"best scores: {self.best_scores}\")\n","        self.logger.info(f\"best thresholds: {self.best_thresholds}\")\n","        self.logger.info(f\"average score: {np.mean(self.best_scores):.5f}\")\n","        self.logger.info(f\"average threshold: {np.mean(self.best_thresholds):.5f}\")\n","    \n","    def save_model(self, model_path, tries=3, delay=5):\n","        for i in range(1, tries + 1):\n","            try:\n","                self.model.save_weights(model_path)\n","            except Exception as e:\n","                self.logger.warning(f\"{e.__class__.__name__}: {e} retry:{i}/{tries}\")\n","                sleep(delay)\n","            else:\n","                return\n","\n","        raise RuntimeError(\"Could not save model\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S31kEJ-a7tMd"},"source":["def train_cv(data_provider, logger, args):\n","    logger.info(args)\n","\n","    for fold in args.folds:\n","        args.update({'fold': fold})\n","        K.clear_session()\n","\n","        seed_everything(args.seed + fold)\n","        model = initialize_tpu_and_get_model(args)\n","\n","        train_dataset = data_provider.create_train_dataset(fold)\n","        valid_dataset, valid_labels = data_provider.create_valid_dataset(fold)\n","\n","        callbacks = [\n","            CalcMetricAndSaveModel(valid_dataset, valid_labels, logger, args)\n","        ]\n","\n","        result = model.fit(\n","            train_dataset,\n","            epochs=args.epochs,\n","            verbose=1,\n","            callbacks=callbacks,\n","            validation_data=valid_dataset,\n","            steps_per_epoch=args.steps_per_epoch,\n","        )\n","        create_graph(result, args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mg_xFUYzU7Ma"},"source":["def evaluate(data_provider, logger, args):\n","    model = initialize_tpu_and_get_model(args)\n","\n","    dir_path = f\"{args.save_dir}/oof_train\"\n","    os.makedirs(dir_path, exist_ok=True)\n","\n","    thresholds = defaultdict(list)\n","    for fold in args.folds:\n","        results = pd.DataFrame()\n","\n","        for idx in range(args.checkpoint.n_best):\n","            save_path = f\"{args.model_dir}/{os.path.basename(args.model_name)}_fold{fold}_{idx}.h5\"\n","            model.load_weights(save_path)\n","\n","            valid_dataset, y_true = data_provider.create_valid_dataset(fold)\n","            y_pred = model.predict(valid_dataset, verbose=1).reshape(-1)\n","\n","            score = calc_score(y_true, y_pred)\n","            log_metrics(logger, fold, score)\n","            \n","            threshold = float(score['threshold'])\n","            results[f\"fold{fold}_{idx}_raw\"] = y_pred\n","            thresholds[f\"fold{fold}\"].append(threshold)\n","        \n","        results.to_csv(f\"{dir_path}/fold{fold}.csv\", index=None)\n","    \n","    thresholds = OmegaConf.create(dict(thresholds))\n","    OmegaConf.save(thresholds, f\"{args.save_dir}/thresholds.yml\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCH1RtWUlUou"},"source":["def predict(data_provider, logger, args):\n","    model = initialize_tpu_and_get_model(args)\n","\n","    results = pd.DataFrame()\n","    for fold in args.folds:\n","        for idx in range(args.checkpoint.n_best):\n","            save_path = f\"{args.model_dir}/{os.path.basename(args.model_name)}_fold{fold}_{idx}.h5\"\n","            model.load_weights(save_path)\n","\n","            test_dataset = data_provider.create_test_dataset() # ここに書かないとだめ\n","            preds = model.predict(test_dataset, verbose=1).reshape(-1)\n","            results[f\"fold{fold}_{idx}_raw\"] = preds\n","    \n","    results.to_csv(f\"{args.save_dir}/oof_test.csv\", index=None)\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8j7f-zF9MhW6"},"source":["def create_submission(preds, args):\n","    submission = pd.read_csv(f\"{args.data_dir}/sample_submit.csv\", header=None)\n","    submission.columns = ['id', 'judgement']\n","    submission['judgement'] = preds\n","    \n","    filepath = f\"{args.save_dir}/submission.csv\"\n","    submission.to_csv(filepath, index=False, header=False)\n","\n","\n","def ensemble(args):\n","    save_dir = f\"{args.drive_dir}/experiments\"\n","\n","    df = pd.DataFrame()\n","    for date in args.dates:\n","        df = pd.concat([df, pd.read_csv(f\"{save_dir}/{date}/oof_test.csv\")], axis=1)\n","\n","    threshold = np.mean(args.thresholds)\n","    preds = (df.mean(axis=1) > threshold).astype(int).values\n","    \n","    create_submission(preds, args)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v1LExfWWdCfC"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"CzHRsXL4vI4L"},"source":["def main(args):\n","    if args.mode == 'ensemble':\n","        ensemble(args)\n","        return\n","    \n","    logger = create_logger(args.save_dir)\n","    df_train, df_test = read_data(args)\n","    data_provider = DataProvider(df_train, df_test, args)\n","\n","    switch = {\n","        'train': train_cv,\n","        'evaluate': evaluate,\n","        'predict': predict,\n","    }\n","    switch[args.mode](data_provider, logger, args)\n","\n","main(args)"],"execution_count":null,"outputs":[]}]}